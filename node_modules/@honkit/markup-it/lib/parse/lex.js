"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const immutable_1 = __importDefault(require("immutable"));
const textToUnstyledTokens_1 = __importDefault(require("./textToUnstyledTokens"));
const matchRule_1 = __importDefault(require("./matchRule"));
/**
 * Process a text using a set of rules
 * to return a flat list of tokens
 *
 * @param {ParsingState} state
 * @param {List<Rule>} rules
 * @param {Boolean} isInline
 * @param {String} text
 * @return {List<Token>}
 */
function lex(state, rules, isInline, text, nonParsed) {
    let tokens = immutable_1.default.List();
    let matchedTokens;
    nonParsed = nonParsed || "";
    if (!text) {
        return tokens.concat(textToUnstyledTokens_1.default(state, isInline, nonParsed));
    }
    rules.forEach((rule) => {
        matchedTokens = matchRule_1.default(state, rule, text);
        if (!matchedTokens) {
            return;
        }
        return false;
    });
    if (!matchedTokens) {
        nonParsed += text[0];
        text = text.substring(1);
        return lex(state, rules, isInline, text, nonParsed);
    }
    const newText = matchedTokens.reduce((result, token) => {
        return result.substring(token.getRaw().length);
    }, text);
    // Keep parsing
    tokens = textToUnstyledTokens_1.default(state, isInline, nonParsed)
        .concat(matchedTokens)
        // @ts-ignore
        .concat(lex(state, rules, isInline, newText));
    return tokens;
}
exports.default = lex;
